{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b23bdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.30.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.51.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.4)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.16.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.15.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\bhoovi\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e645a2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\BHOOVI\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import models, layers, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cf36f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/Users/srirammandalika/Downloads/tusimple_preprocessed/training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b8969d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/Users/srirammandalika/Downloads/tusimple_preprocessed/training'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18788\\2806501349.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimg_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m images_set = img_generator.flow_from_directory(\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtrain_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1647\u001b[0m             \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1648\u001b[0m         \"\"\"\n\u001b[1;32m-> 1649\u001b[1;33m         return DirectoryIterator(\n\u001b[0m\u001b[0;32m   1650\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1651\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/Users/srirammandalika/Downloads/tusimple_preprocessed/training'"
     ]
    }
   ],
   "source": [
    "# create a generator and get the images from the directory\n",
    "img_generator = keras.preprocessing.image.ImageDataGenerator()\n",
    "seed = 10\n",
    "images_set = img_generator.flow_from_directory(\n",
    "    train_path,\n",
    "    shuffle=False,\n",
    "    batch_size=64,\n",
    "    class_mode='binary',\n",
    "    target_size=(256, 320)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f412e207",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18788\\2130754755.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# loop over the batches and extract the images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mbatch_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# this contains the images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mbatch_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# this contains 0s and 1s\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'images_set' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Assign the images in 'images_set' to two seperate arrays:\n",
    "assign the road images to 'X' and the ground truth masks to 'Y'\n",
    "'''\n",
    "num_images = 7252 # gotten from the output of the cell above\n",
    "num_batches = num_images // 64 + 1\n",
    "\n",
    "# initialize an empty list to store the images\n",
    "X = []\n",
    "Y = []\n",
    "# loop over the batches and extract the images\n",
    "for i in range(num_batches):\n",
    "    batch = next(images_set)\n",
    "    batch_images = batch[0] # this contains the images\n",
    "    batch_labels = batch[1] # this contains 0s and 1s\n",
    "    for ind, lb in enumerate(batch_labels):\n",
    "        '''\n",
    "        a label of 0 means the image belongs to ground truth image,\n",
    "        and a label of 1 means that the image belongs to the ground truth mask\n",
    "        '''\n",
    "        if lb == 0: \n",
    "            X.append(batch_images[ind])\n",
    "        else:\n",
    "            Y.append(np.mean(batch_images[ind], axis=2)) # Y shape is (m, 256, 320)\n",
    "    if i % 10 == 0:\n",
    "        print(f'Batch {i}')\n",
    "\n",
    "# convert the lists to numpy arrays\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5da7e559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the dataset\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X, Y = shuffle(X, Y, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4655966d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18788\\348489576.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Normalize and reshape the mask set (Y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m320\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: '>=' not supported between instances of 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "# Normalize and reshape the mask set (Y)\n",
    "Y = (Y >= 100).astype('int').reshape(-1, 256, 320, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ef87d58",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'min'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18788\\4077669706.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'min'"
     ]
    }
   ],
   "source": [
    "Y.min(), Y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5050711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we get 2000 images for training and evaluation\n",
    "X = np.array(X[:2000])\n",
    "Y = np.array(Y[:2000])\n",
    "\n",
    "\n",
    "# Split the datset into train and val sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=.1, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba749f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (1800, 256, 320, 3)\n",
      "Shape of X_val: (200, 256, 320, 3)\n",
      "Shape of Y_train: (1800, 256, 320, 1)\n",
      "Shape of Y_val: (200, 256, 320, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_val:\", X_val.shape)\n",
    "print(\"Shape of Y_train:\", Y_train.shape)\n",
    "print(\"Shape of Y_val:\", Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "883cf705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# free the RAM from undesired clutters\n",
    "import gc\n",
    "del X, Y, images_set\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ca88f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model's architecture\n",
    "\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "def unet(input_size=(256,320,3)):\n",
    "    inputs = Input(input_size)\n",
    "    rescale = keras.layers.Rescaling(1./255)(inputs)\n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(rescale)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    \n",
    "    # Decoder\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    \n",
    "    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(drop5))\n",
    "    merge6 = Concatenate(axis=3)([conv4, up6])\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "    \n",
    "    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv6))\n",
    "    merge7 = Concatenate(axis=3)([conv3, up7])\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "    \n",
    "    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv7))\n",
    "    merge8 = Concatenate(axis=3)([conv2, up8])\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "    \n",
    "    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv8))\n",
    "    merge9 = Concatenate(axis=3)([conv1, up9])\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    \n",
    "    outputs = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e3810bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 320, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " rescaling (Rescaling)       (None, 256, 320, 3)          0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 256, 320, 64)         1792      ['rescaling[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 256, 320, 64)         36928     ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 128, 160, 64)         0         ['conv2d_1[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 128, 160, 128)        73856     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 128, 160, 128)        147584    ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 64, 80, 128)          0         ['conv2d_3[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 64, 80, 256)          295168    ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 64, 80, 256)          590080    ['conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 32, 40, 256)          0         ['conv2d_5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 32, 40, 512)          1180160   ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 32, 40, 512)          2359808   ['conv2d_6[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 16, 20, 512)          0         ['conv2d_7[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 16, 20, 1024)         4719616   ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 16, 20, 1024)         9438208   ['conv2d_8[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 16, 20, 1024)         0         ['conv2d_9[0][0]']            \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2  (None, 32, 40, 1024)         0         ['dropout[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 32, 40, 512)          2097664   ['up_sampling2d[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 32, 40, 1024)         0         ['conv2d_7[0][0]',            \n",
      "                                                                     'conv2d_10[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 32, 40, 512)          4719104   ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 32, 40, 512)          2359808   ['conv2d_11[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSamplin  (None, 64, 80, 512)          0         ['conv2d_12[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 64, 80, 256)          524544    ['up_sampling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 64, 80, 512)          0         ['conv2d_5[0][0]',            \n",
      " )                                                                   'conv2d_13[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 64, 80, 256)          1179904   ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 64, 80, 256)          590080    ['conv2d_14[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSamplin  (None, 128, 160, 256)        0         ['conv2d_15[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 128, 160, 128)        131200    ['up_sampling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 128, 160, 256)        0         ['conv2d_3[0][0]',            \n",
      " )                                                                   'conv2d_16[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 128, 160, 128)        295040    ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 128, 160, 128)        147584    ['conv2d_17[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSamplin  (None, 256, 320, 128)        0         ['conv2d_18[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 256, 320, 64)         32832     ['up_sampling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 256, 320, 128)        0         ['conv2d_1[0][0]',            \n",
      " )                                                                   'conv2d_19[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 256, 320, 64)         73792     ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 256, 320, 64)         36928     ['conv2d_20[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 256, 320, 1)          65        ['conv2d_21[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31031745 (118.38 MB)\n",
      "Trainable params: 31031745 (118.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=keras.losses.BinaryFocalCrossentropy(), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3982e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 47/113 [===========>..................] - ETA: 55:29 - loss: 0.9835 - accuracy: 0.9374"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "# Define the path to the folder where you want to save TensorBoard logs\n",
    "# Update this path to a suitable directory on your local machine\n",
    "tensorboard_log_dir = './logs'\n",
    "\n",
    "# Create a TensorBoard callback\n",
    "tensorboard_callback = TensorBoard(log_dir=tensorboard_log_dir, histogram_freq=1)\n",
    "\n",
    "# Define epochs and batch_size for training\n",
    "epochs = 20\n",
    "batch_size = 16\n",
    "\n",
    "# Define callbacks for model checkpointing and TensorBoard\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
    "    tensorboard_callback,\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48947657",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_val)\n",
    "preds.max(), preds.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50353c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some results from the val set.\n",
    "plt.figure(figsize=(10, 45))\n",
    "s, e = 90, 98\n",
    "index = 1\n",
    "\n",
    "preds = (preds >= .5).astype('int')\n",
    "for i, j, k in zip(X_val[s:e], preds[s:e], Y_val[s:e]):\n",
    "    # write these images into file as well\n",
    "    cv2.imwrite(f'./out/img-{index}.jpg', i)\n",
    "    cv2.imwrite(f'./out/pred-{index}.jpg', j*255.)\n",
    "    cv2.imwrite(f'./out/ground-{index}.jpg', k*255.)\n",
    "    \n",
    "    plt.subplot(10, 2, index)\n",
    "    plt.imshow(i/255.)\n",
    "    plt.title('Ground truth image')\n",
    "    \n",
    "    plt.subplot(10, 2, index+1)\n",
    "    plt.imshow(j, cmap='gray')\n",
    "    plt.title('Pred mask')\n",
    "    index += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297185d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create metrices\n",
    "accuracy = tf.keras.metrics.Accuracy()\n",
    "precision = tf.keras.metrics.Precision()\n",
    "recal = tf.keras.metrics.Recall()\n",
    "iou = tf.keras.metrics.IoU(num_classes=2, target_class_ids=[1])\n",
    "\n",
    "\n",
    "# accuracy\n",
    "accuracy.update_state(Y_val, preds)\n",
    "accuracy_value = accuracy.result().numpy()\n",
    "# precision\n",
    "precision.update_state(Y_val, preds)\n",
    "precision_value = precision.result().numpy()\n",
    "# recal\n",
    "recal.update_state(Y_val, preds)\n",
    "recal_value = recal.result().numpy()\n",
    "# f1 score\n",
    "f1_score = 2 / ((1 / precision_value) + (1 / recal_value))\n",
    "\n",
    "# Intersection over union (IoU)\n",
    "iou.update_state(Y_val, preds)\n",
    "iou_value = iou.result().numpy()\n",
    "\n",
    "print(\"Accuracy:\", accuracy_value)\n",
    "print(\"Precision:\", precision_value)\n",
    "print(\"Recall:\", recal_value)\n",
    "print('F1 Score: ', f1_score)\n",
    "print('IoU: ', iou_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf2e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create metrices\n",
    "accuracy = tf.keras.metrics.Accuracy()\n",
    "precision = tf.keras.metrics.Precision()\n",
    "recal = tf.keras.metrics.Recall()\n",
    "iou = tf.keras.metrics.IoU(num_classes=2, target_class_ids=[1])\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "# Calculate MSE\n",
    "mse_value = mean_squared_error(Y_val.flatten(), preds.flatten())\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_value = math.sqrt(mse_value)\n",
    "# accuracy\n",
    "accuracy.update_state(Y_val, preds)\n",
    "accuracy_value = accuracy.result().numpy()\n",
    "# precision\n",
    "precision.update_state(Y_val, preds)\n",
    "precision_value = precision.result().numpy()\n",
    "# recal\n",
    "recal.update_state(Y_val, preds)\n",
    "recal_value = recal.result().numpy()\n",
    "# f1 score\n",
    "f1_score = 2 / ((1 / precision_value) + (1 / recal_value))\n",
    "\n",
    "# Intersection over union (IoU)\n",
    "iou.update_state(Y_val, preds)\n",
    "iou_value = iou.result().numpy()\n",
    "\n",
    "print(\"Accuracy:\", accuracy_value)\n",
    "print(\"Precision:\", precision_value)\n",
    "print(\"Recall:\", recal_value)\n",
    "print('F1 Score: ', f1_score)\n",
    "print('IoU: ', iou_value)\n",
    "# Print the results\n",
    "print(\"Mean Squared Error (MSE):\", mse_value)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed05d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation metrics with markers for starting and ending points\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.subplot(2, 1, 1)  # Two subplots in a vertical arrangement\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss', marker='o')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.ylim(-0.1, 1.1)  # Set y-axis limits for loss with padding\n",
    "\n",
    "# Display values for starting and ending points on the loss plot\n",
    "start_loss_coord = (0, history.history['loss'][0])\n",
    "end_loss_coord = (epochs-1, history.history['loss'][-1])\n",
    "plt.text(*start_loss_coord, f'({start_loss_coord[0]}, {start_loss_coord[1]:.4f})', color='green', fontsize=10, ha='right', weight='bold')\n",
    "plt.text(*end_loss_coord, f'({end_loss_coord[0]}, {end_loss_coord[1]:.4f})', color='red', fontsize=10, ha='right', weight='bold')\n",
    "\n",
    "plt.subplot(2, 1, 2)  # Second subplot for accuracy\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.ylim(-0.1, 1.1)  # Set y-axis limits for accuracy with padding\n",
    "\n",
    "# Display values for starting and ending points on the accuracy plot\n",
    "start_accuracy_coord = (0, history.history['accuracy'][0])\n",
    "end_accuracy_coord = (epochs-1, history.history['accuracy'][-1])\n",
    "plt.text(*start_accuracy_coord, f'({start_accuracy_coord[0]}, {start_accuracy_coord[1]:.4f})', color='green', fontsize=10, ha='right', weight='bold')\n",
    "plt.text(*end_accuracy_coord, f'({end_accuracy_coord[0]}, {end_accuracy_coord[1]:.4f})', color='red', fontsize=10, ha='right', weight='bold')\n",
    "\n",
    "plt.tight_layout()  # Adjust layout for better visualization\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0029474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation metrics with markers for starting and ending points\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.subplot(2, 1, 1)  # Two subplots in a vertical arrangement\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss', marker='o')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.ylim(-0.1, 1.1)  # Set y-axis limits for loss with padding\n",
    "\n",
    "# Display values for starting and ending points on the loss plot\n",
    "start_loss_coord = (0, history.history['loss'][0])\n",
    "end_loss_coord = (epochs-1, history.history['loss'][-1])\n",
    "plt.text(*start_loss_coord, f'({start_loss_coord[0]}, {start_loss_coord[1]:.4f})', color='green', fontsize=10, ha='right', weight='bold')\n",
    "plt.text(*end_loss_coord, f'({end_loss_coord[0]}, {end_loss_coord[1]:.4f})', color='red', fontsize=10, ha='right', weight='bold')\n",
    "\n",
    "plt.subplot(2, 1, 2)  # Second subplot for accuracy\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.ylim(-0.1, 1.1)  # Set y-axis limits for accuracy with padding\n",
    "\n",
    "# Display values for starting and ending points on the accuracy plot\n",
    "start_accuracy_coord = (0, history.history['accuracy'][0])\n",
    "end_accuracy_coord = (epochs-1, history.history['accuracy'][-1])\n",
    "plt.text(*start_accuracy_coord, f'({start_accuracy_coord[0]}, {start_accuracy_coord[1]:.4f})', color='green', fontsize=10, ha='right', weight='bold')\n",
    "plt.text(*end_accuracy_coord, f'({end_accuracy_coord[0]}, {end_accuracy_coord[1]:.4f})', color='red', fontsize=10, ha='right', weight='bold')\n",
    "\n",
    "plt.tight_layout()  # Adjust layout for better visualization\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig('training_validation_plot.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74653b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECALL CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328ac16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Calculate recall\n",
    "recall_val = recall_score(Y_val.flatten(), preds.flatten())\n",
    "\n",
    "# Plot Recall Curve\n",
    "plt.plot([0, 1], [0, recall_val], label=f'Recall: {recall_val:.4f}', marker='o')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('recall_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee3b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRECISION CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8d570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Calculate precision\n",
    "precision_val = precision_score(Y_val.flatten(), preds.flatten())\n",
    "\n",
    "# Plot Precision Curve\n",
    "plt.plot([0, 1], [0, precision_val], label=f'Precision: {precision_val:.4f}', marker='o')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('precision_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0defa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRECISION RECALL CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db77f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Calculate precision-recall curve values\n",
    "precision, recall, _ = precision_recall_curve(Y_val.flatten(), preds.flatten())\n",
    "\n",
    "# Plot Recall-Precision Curve\n",
    "plt.plot(recall, precision, label='Recall-Precision Curve', marker='o')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Recall-Precision Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('recall_precision_curve.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42460985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbf6e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1_score_val = f1_score(Y_val.flatten(), preds.flatten())\n",
    "\n",
    "# Plot F1 Score Curve\n",
    "plt.plot([0, 1], [0, f1_score_val], label=f'F1 Score: {f1_score_val:.4f}', marker='o')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('f1_score_curve.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff841103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACCURACY CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4b6bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Accuracy Curve\n",
    "plt.plot([0, 1], [0, accuracy_value], label=f'Accuracy: {accuracy_value:.4f}', marker='o')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('accuracy_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd133ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
